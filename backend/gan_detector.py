"""
GAN Detector for DeepDefend
Specialized detector for GAN-generated images with focus on deepfakes
"""

import cv2
import numpy as np
import logging
from typing import Dict, Any, List, Tuple, Optional
import os
import tensorflow as tf
from scipy import fftpack

# Configure logging
logger = logging.getLogger(__name__)

class GANDetector:
    """
    Specialized detector for GAN-generated images
    """
    
    def __init__(self, model_path: str = None):
        """
        Initialize the GAN detector
        
        Args:
            model_path: Optional path to a custom GAN detection model
        """
        self.model_path = model_path
        self.model = None
        
        # Load model if provided
        if model_path and os.path.exists(model_path):
            try:
                self.model = tf.keras.models.load_model(model_path)
                logger.info(f"Loaded GAN detection model from {model_path}")
            except Exception as e:
                logger.error(f"Failed to load GAN detection model: {str(e)}")
        
        logger.info("GAN detector initialized")
    
    def detect(self, image: np.ndarray) -> Dict[str, Any]:
        """
        Detect if an image was generated by a GAN
        
        Args:
            image: Input image in BGR format
            
        Returns:
            Dictionary with detection results
        """
        try:
            # If we have a model, use it
            if self.model is not None:
                return self._detect_with_model(image)
            
            # Otherwise use rule-based detection
            return self._detect_with_rules(image)
            
        except Exception as e:
            logger.error(f"Error in GAN detection: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "gan_probability": 0.5,
                "confidence": 0.1
            }
    
    def _detect_with_model(self, image: np.ndarray) -> Dict[str, Any]:
        """
        Detect GAN-generated image using a trained model
        
        Args:
            image: Input image in BGR format
            
        Returns:
            Dictionary with detection results
        """
        # Preprocess image
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        resized = cv2.resize(rgb_image, (224, 224))
        normalized = resized / 255.0
        input_tensor = np.expand_dims(normalized, axis=0)
        
        # Get prediction
        prediction = self.model.predict(input_tensor, verbose=0)
        gan_probability = float(prediction[0][0])
        
        # Calculate confidence based on prediction distance from 0.5
        confidence = abs(gan_probability - 0.5) * 2.0
        
        return {
            "success": True,
            "gan_probability": gan_probability,
            "confidence": confidence,
            "method": "model-based",
            "artifacts": self._detect_gan_artifacts(image)
        }
    
    def _detect_with_rules(self, image: np.ndarray) -> Dict[str, Any]:
        """
        Detect GAN-generated image using rule-based methods
        
        Args:
            image: Input image in BGR format
            
        Returns:
            Dictionary with detection results
        """
        # Analyze frequency domain artifacts
        freq_score = self._analyze_frequency_domain(image)
        
        # Analyze noise patterns
        noise_score = self._analyze_noise_patterns(image)
        
        # Analyze color inconsistencies
        color_score = self._analyze_color_inconsistencies(image)
        
        # Analyze texture patterns
        texture_score = self._analyze_texture_patterns(image)
        
        # Calculate overall GAN probability
        # Weight the scores based on reliability
        gan_probability = (
            freq_score * 0.4 +
            noise_score * 0.3 +
            color_score * 0.2 +
            texture_score * 0.1
        )
        
        # Calculate confidence
        # Higher if individual scores agree with each other
        scores = [freq_score, noise_score, color_score, texture_score]
        agreement = 1.0 - np.std(scores)
        confidence = agreement * 0.7  # Scale to reasonable confidence level
        
        # Detect specific GAN artifacts
        artifacts = self._detect_gan_artifacts(image)
        
        return {
            "success": True,
            "gan_probability": float(gan_probability),
            "confidence": float(confidence),
            "method": "rule-based",
            "scores": {
                "frequency_domain": float(freq_score),
                "noise_patterns": float(noise_score),
                "color_inconsistencies": float(color_score),
                "texture_patterns": float(texture_score)
            },
            "artifacts": artifacts
        }
    
    def _analyze_frequency_domain(self, image: np.ndarray) -> float:
        """
        Analyze frequency domain for GAN artifacts
        
        Args:
            image: Input image in BGR format
            
        Returns:
            Score indicating likelihood of GAN generation (0-1)
        """
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Apply FFT
        f = np.fft.fft2(gray)
        fshift = np.fft.fftshift(f)
        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1)
        
        # Normalize
        magnitude_spectrum = cv2.normalize(magnitude_spectrum, None, 0, 1, cv2.NORM_MINMAX)
        
        # Calculate radial average
        h, w = magnitude_spectrum.shape
        center_y, center_x = h // 2, w // 2
        y, x = np.ogrid[:h, :w]
        dist_from_center = np.sqrt((x - center_x)**2 + (y - center_y)**2)
        
        # Create radial bins
        max_radius = min(center_x, center_y)
        num_bins = 20
        radial_bins = np.linspace(0, max_radius, num_bins + 1)
        
        # Calculate radial profile
        radial_profile = np.zeros(num_bins)
        for i in range(num_bins):
            bin_mask = (dist_from_center >= radial_bins[i]) & (dist_from_center < radial_bins[i+1])
            radial_profile[i] = np.mean(magnitude_spectrum[bin_mask])
        
        # Normalize profile
        if np.max(radial_profile) > 0:
            radial_profile = radial_profile / np.max(radial_profile)
        
        # Calculate features from profile
        # GAN images often have more energy in mid-frequencies
        low_freq = np.mean(radial_profile[:5])
        mid_freq = np.mean(radial_profile[5:15])
        high_freq = np.mean(radial_profile[15:])
        
        # Calculate GAN score based on frequency distribution
        # Higher mid-frequency energy relative to low/high is suspicious
        gan_score = mid_freq / (low_freq + high_freq + 1e-10)
        
        # Normalize to 0-1 range
        gan_score = min(1.0, gan_score / 2.0)
        
        return gan_score
    
    def _analyze_noise_patterns(self, image: np.ndarray) -> float:
        """
        Analyze noise patterns for GAN detection
        
        Args:
            image: Input image in BGR format
            
        Returns:
            Score indicating likelihood of GAN generation (0-1)
        """
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Apply Gaussian blur to remove high-frequency noise
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # Calculate noise by subtracting blurred from original
        noise = cv2.subtract(gray, blurred)
        
        # Calculate noise statistics
        noise_mean = np.mean(noise)
        noise_std = np.std(noise)
        noise_entropy = self._calculate_entropy(noise)
        
        # Calculate local noise variance
        local_var = cv2.Laplacian(noise, cv2.CV_64F).var()
        
        # GAN-generated images often have specific noise characteristics
        # - More uniform noise distribution
        # - Lower entropy
        # - Lower local variance
        
        # Calculate uniformity score (higher = more uniform = more suspicious)
        uniformity = 1.0 - min(1.0, noise_std / 15.0)
        
        # Calculate entropy score (lower entropy = more suspicious)
        entropy_score = 1.0 - min(1.0, noise_entropy / 5.0)
        
        # Calculate local variance score (lower variance = more suspicious)
        variance_score = 1.0 - min(1.0, local_var / 100.0)
        
        # Combine scores
        gan_score = (uniformity * 0.4 + entropy_score * 0.4 + variance_score * 0.2)
        
        return gan_score
    
    def _analyze_color_inconsistencies(self, image: np.ndarray) -> float:
        """
        Analyze color inconsistencies for GAN detection
        
        Args:
            image: Input image in BGR format
            
        Returns:
            Score indicating likelihood of GAN generation (0-1)
        """
        # Convert to different color spaces
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)
        
        # Split channels
        h, s, v = cv2.split(hsv)
        l, a, b = cv2.split(lab)
        
        # Calculate color statistics
        h_stats = self._calculate_channel_stats(h)
        s_stats = self._calculate_channel_stats(s)
        v_stats = self._calculate_channel_stats(v)
        a_stats = self._calculate_channel_stats(a)
        b_stats = self._calculate_channel_stats(b)
        
        # GAN-generated images often have:
        # - Unnatural hue distribution
        # - Oversaturated or undersaturated colors
        # - Unusual a/b channel distributions
        
        # Calculate hue distribution score
        h_entropy = self._calculate_entropy(h)
        hue_score = 1.0 - min(1.0, h_entropy / 5.0)
        
        # Calculate saturation score
        sat_score = 0.0
        if s_stats["mean"] > 150:  # Oversaturated
            sat_score = min(1.0, (s_stats["mean"] - 150) / 100)
        elif s_stats["mean"] < 50:  # Undersaturated
            sat_score = min(1.0, (50 - s_stats["mean"]) / 50)
        
        # Calculate a/b channel score
        ab_score = 0.0
        if a_stats["std"] < 5 or b_stats["std"] < 5:  # Too uniform
            ab_score = 1.0 - min(1.0, (a_stats["std"] + b_stats["std"]) / 10.0)
        
        # Combine scores
        gan_score = (hue_score * 0.3 + sat_score * 0.4 + ab_score * 0.3)
        
        return gan_score
    
    def _analyze_texture_patterns(self, image: np.ndarray) -> float:
        """
        Analyze texture patterns for GAN detection
        
        Args:
            image: Input image in BGR format
            
        Returns:
            Score indicating likelihood of GAN generation (0-1)
        """
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Calculate gradient
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)
        
        # Calculate gradient statistics
        grad_mean = np.mean(gradient_magnitude)
        grad_std = np.std(gradient_magnitude)
        grad_entropy = self._calculate_entropy(gradient_magnitude.astype(np.uint8))
        
        # GAN-generated images often have:
        # - More uniform gradient distribution
        # - Lower gradient entropy
        
        # Calculate uniformity score
        uniformity = 1.0 - min(1.0, grad_std / grad_mean / 2.0)
        
        # Calculate entropy score
        entropy_score = 1.0 - min(1.0, grad_entropy / 5.0)
        
        # Combine scores
        gan_score = (uniformity * 0.6 + entropy_score * 0.4)
        
        return gan_score
    
    def _detect_gan_artifacts(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Detect specific GAN artifacts in the image
        
        Args:
            image: Input image in BGR format
            
        Returns:
            List of detected artifacts
        """
        artifacts = []
        
        # Check for unnatural eyes (common in GAN faces)
        eye_artifacts = self._check_eye_artifacts(image)
        if eye_artifacts:
            artifacts.extend(eye_artifacts)
        
        # Check for unnatural hair
        hair_artifacts = self._check_hair_artifacts(image)
        if hair_artifacts:
            artifacts.extend(hair_artifacts)
        
        # Check for background inconsistencies
        bg_artifacts = self._check_background_artifacts(image)
        if bg_artifacts:
            artifacts.extend(bg_artifacts)
        
        # Check for symmetry issues
        symmetry_artifacts = self._check_symmetry_artifacts(image)
        if symmetry_artifacts:
            artifacts.extend(symmetry_artifacts)
        
        return artifacts
    
    def _check_eye_artifacts(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Check for unnatural eye artifacts
        
        Args:
            image: Input image in BGR format
            
        Returns:
            List of detected eye artifacts
        """
        # This would normally use face detection and eye detection
        # For simplicity, we'll use a basic implementation
        
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Detect faces
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        
        artifacts = []
        
        for (x, y, w, h) in faces:
            # Define eye region
            eye_region = gray[y:y+h//2, x:x+w]
            
            # Apply threshold to detect bright spots (eye reflections)
            _, thresh = cv2.threshold(eye_region, 200, 255, cv2.THRESH_BINARY)
            
            # Count bright spots
            num_spots = cv2.countNonZero(thresh)
            
            # If too many or too few bright spots, flag as artifact
            if num_spots > 100 or num_spots < 5:
                artifacts.append({
                    "type": "unnatural_eyes",
                    "description": "Unnatural eye reflections or patterns",
                    "severity": 0.7,
                    "location": "eyes"
                })
                break
        
        return artifacts
    
    def _check_hair_artifacts(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Check for unnatural hair artifacts
        
        Args:
            image: Input image in BGR format
            
        Returns:
            List of detected hair artifacts
        """
        # This would normally use semantic segmentation
        # For simplicity, we'll use a basic implementation
        
        # Convert to HSV
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # Extract saturation channel
        _, s, _ = cv2.split(hsv)
        
        # Calculate saturation statistics for upper part of image
        h, w = image.shape[:2]
        upper_region = s[0:h//3, :]
        
        sat_mean = np.mean(upper_region)
        sat_std = np.std(upper_region)
        
        artifacts = []
        
        # Check for unnaturally uniform hair
        if sat_std < 20 and sat_mean > 100:
            artifacts.append({
                "type": "unnatural_hair",
                "description": "Unnaturally uniform hair texture",
                "severity": 0.6,
                "location": "hair"
            })
        
        return artifacts
    
    def _check_background_artifacts(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Check for background artifacts
        
        Args:
            image: Input image in BGR format
            
        Returns:
            List of detected background artifacts
        """
        # This would normally use background segmentation
        # For simplicity, we'll use a basic implementation
        
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Apply Gaussian blur
        blurred = cv2.GaussianBlur(gray, (15, 15), 0)
        
        # Apply Canny edge detection
        edges = cv2.Canny(blurred, 50, 150)
        
        # Count edges in border region
        h, w = edges.shape
        border_width = 20
        border_mask = np.zeros_like(edges)
        border_mask[0:border_width, :] = 1
        border_mask[h-border_width:h, :] = 1
        border_mask[:, 0:border_width] = 1
        border_mask[:, w-border_width:w] = 1
        
        border_edges = cv2.bitwise_and(edges, edges, mask=border_mask)
        edge_count = cv2.countNonZero(border_edges)
        
        artifacts = []
        
        # Check for unnaturally few edges in border
        if edge_count < 100:
            artifacts.append({
                "type": "unnatural_background",
                "description": "Unnaturally smooth or uniform background",
                "severity": 0.5,
                "location": "background"
            })
        
        return artifacts
    
    def _check_symmetry_artifacts(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Check for symmetry artifacts
        
        Args:
            image: Input image in BGR format
            
        Returns:
            List of detected symmetry artifacts
        """
        # This would normally use face landmarks
        # For simplicity, we'll use a basic implementation
        
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Get image dimensions
        h, w = gray.shape
        
        # Split image into left and right halves
        left_half = gray[:, :w//2]
        right_half = gray[:, w//2:]
        
        # Flip right half
        right_half_flipped = cv2.flip(right_half, 1)
        
        # Resize if needed
        if left_half.shape[1] != right_half_flipped.shape[1]:
            min_width = min(left_half.shape[1], right_half_flipped.shape[1])
            left_half = left_half[:, :min_width]
            right_half_flipped = right_half_flipped[:, :min_width]
        
        # Calculate difference
        diff = cv2.absdiff(left_half, right_half_flipped)
        
        # Calculate mean difference
        mean_diff = np.mean(diff)
        
        artifacts = []
        
        # Check for unnaturally high symmetry
        if mean_diff < 10:
            artifacts.append({
                "type": "unnatural_symmetry",
                "description": "Unnaturally high facial symmetry",
                "severity": 0.7,
                "location": "face"
            })
        
        return artifacts
    
    def _calculate_entropy(self, image: np.ndarray) -> float:
        """
        Calculate entropy of an image
        
        Args:
            image: Input image
            
        Returns:
            Entropy value
        """
        # Calculate histogram
        hist = cv2.calcHist([image], [0], None, [256], [0, 256])
        
        # Normalize histogram
        hist = hist / np.sum(hist)
        
        # Remove zeros
        hist = hist[hist > 0]
        
        # Calculate entropy
        entropy = -np.sum(hist * np.log2(hist))
        
        return entropy
    
    def _calculate_channel_stats(self, channel: np.ndarray) -> Dict[str, float]:
        """
        Calculate statistics for a color channel
        
        Args:
            channel: Color channel
            
        Returns:
            Dictionary with channel statistics
        """
        return {
            "mean": float(np.mean(channel)),
            "std": float(np.std(channel)),
            "min": float(np.min(channel)),
            "max": float(np.max(channel)),
            "median": float(np.median(channel))
        }


# Create a singleton instance
_gan_detector_instance = None

def get_gan_detector() -> GANDetector:
    """
    Get the singleton GAN detector instance
    
    Returns:
        GANDetector instance
    """
    global _gan_detector_instance
    if _gan_detector_instance is None:
        _gan_detector_instance = GANDetector()
    return _gan_detector_instance

def detect_gan(image: np.ndarray) -> Dict[str, Any]:
    """
    Detect if an image was generated by a GAN
    
    Args:
        image: Input image in BGR format
        
    Returns:
        Dictionary with detection results
    """
    detector = get_gan_detector()
    return detector.detect(image)